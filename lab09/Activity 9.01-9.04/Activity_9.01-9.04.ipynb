{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of a practical data wrangling task\n",
    "\n",
    "In this Notebook, we will show a practical data wrangling task step-by-step - how it is structured, what you should watch for, and how to improvise.\n",
    "\n",
    "### The task\n",
    "Imagine the question: ***\"In India, did the enrollment in primary/secondary/tertiary education increase with improvement of per capita GDP in the past 15 years?\"***\n",
    "\n",
    "Now, the actual modeling and analysis will be done by some senior data scientist, who will use some machine learning and visualization for the job. As a data wrangling expert, **your job is to acquire and provide her with a clean dataset which contains educational enrollment and GDP data side by side.**\n",
    "\n",
    "### The data source\n",
    "\n",
    "Suppose you have a link for a **[dataset from the United Nations](http://data.un.org)** and you can download the dataset of education (for all the nations around the world). But this dataset has some missing values and moreover it does not have any GDP information. Someone has given you another separate CSV file (downloaded from the World Bank site) which contains GDP data but in a messy format.\n",
    "\n",
    "In this notebook, we will examine how to handle these two separate sources and to clean the data to prepare a simple final dataset with the required data and save it to the local drive as a SQL database file.\n",
    "\n",
    "The link for the education data: http://data.un.org/_Docs/SYB/CSV/SYB61_T07_Education.csv\n",
    "\n",
    "The link for the GDP data (hosted on Github repository for this course): https://github.com/fenago/data-wrangling-python/blob/master/lab09/datasets/India_World_Bank_Info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_data_link=\"http://data.un.org/_Docs/SYB/CSV/SYB61_T07_Education.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `pd.read_csv()` method of Pandas to directly pass this link and create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(education_data_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first row does not contain useful information. We should use `skiprows` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(education_data_link,skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the column `Region/Country/Area` and `Source`. They don't look useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(['Region/Country/Area','Source'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign the following names as the columns of the dataframe: `['Region/Country/Area','Year','Data','Value','Footnotes']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns=['Region/Country/Area','Year','Data','Enrollments (Thousands)','Footnotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why don't we drop the `Footnotes` column?\n",
    "\n",
    "If you download the CSV file and open it using Excel then you will see the `Footnotes` column sometimes contain useful notes. We may not want to drop it in the beginning. If we are interested in particular country's data (like we are in this task) then it may well turn out that `Footnotes` will be `NaN` i.e. blank. In that case, we can drop it at the end. But for some countries or region it may contain information.\n",
    "\n",
    "We can, of course, check how many unique values the `Footnotes` column contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Footnotes'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Value` column data is not numeric but we need them to be numbers for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df2['Enrollments (Thousands)'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a small utility function to convert the strings in `Value` column to floating point numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(val):\n",
    "    \"\"\"\n",
    "    Converts a given string (with one or more commas) to a numeric value\n",
    "    \"\"\"\n",
    "    if ',' not in str(val):\n",
    "        result = float(val)\n",
    "    else:\n",
    "        val=str(val)\n",
    "        val=''.join(str(val).split(','))\n",
    "        result=float(val)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the `apply()` method to apply this function to the `Value` column data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Enrollments (Thousands)']=df2['Enrollments (Thousands)'].apply(to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print unique types of data in the `Data` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Data'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create three DataFrames by filtering and selecting from the original DataFrame\n",
    "* **`df_primary`**: Only *\"Students enrolled in primary education (thousands)\"*\n",
    "* **`df_secondary`**: Only *\"Students enrolled in secondary education (thousands)\"*\n",
    "* **`df_tertiary`**: Only *\"Students enrolled in tertiary education (thousands)\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primary = df2[df2['Data']=='Students enrolled in primary education (thousands)']\n",
    "df_secondary = df2[df2['Data']=='Students enrolled in secondary education (thousands)']\n",
    "df_tertiary = df2[df2['Data']=='Students enrolled in tertiary education (thousands)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make bar charts of primary students enrollment in a low-income country like India and a high-income country like USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india = df_primary[df_primary['Region/Country/Area']=='India']\n",
    "primary_enrollment_USA = df_primary[df_primary['Region/Country/Area']=='United States of America']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(primary_enrollment_india['Year'],primary_enrollment_india['Enrollments (Thousands)'])\n",
    "plt.title(\"Enrollment in primary education\\nin India (in thousands)\",fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(primary_enrollment_USA['Year'],primary_enrollment_USA['Enrollments (Thousands)'])\n",
    "plt.title(\"Enrollment in primary education\\nin the United States of America (in thousands)\",fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imputation\n",
    "\n",
    "Clearly, we are missing some data. Let's say we decide to **impute these data points by simple linear interpolation between available data points.**\n",
    "\n",
    "We can take out a pen and paper or a calculator, and compute those values and manually create a dataset somewhow. But being a data wrangler, we will of course take advantage of Python programming, and use Pandas imputation methods for this task. \n",
    "\n",
    "But to do that, we first need to create a dataframe with missing values inserted which means we need to append another dataframe with missing values to the current dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (For India) Append rows corresponding to missing years - 2004 - 2009, 2011 - 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_years = [y for y in range(2004,2010)]+[y for y in range(2011,2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a dictionary of values with `np.nan`.  Note, there are 9 mising data points, so we need to create list with identical values repeated 9 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_missing = {'Region/Country/Area':['India']*9,'Year':missing_years,\n",
    "                'Data':'Students enrolled in primary education (thousands)'*9,\n",
    "                'Enrollments (Thousands)':[np.nan]*9,'Footnotes':[np.nan]*9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe of missing values (from the dictionary above) which we can append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = pd.DataFrame(data=dict_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india=primary_enrollment_india.append(df_missing,ignore_index=True,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by `Year` and reset the indices using `reset_index()`. Use `inplace=True` to execute the changes on the dataframe itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india.sort_values(by='Year',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `interpolate` method for linear interpolation. It fills all the `NaN` by linearly interpolated values.\n",
    "\n",
    "See this link for more details about this method: http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.interpolate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(primary_enrollment_india['Year'],primary_enrollment_india['Enrollments (Thousands)'])\n",
    "plt.title(\"Enrollment in primary education\\nin India (in thousands)\",fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat the same steps for USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_years = [2004]+[y for y in range(2006,2010)]+[y for y in range(2011,2014)]+[2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_missing = {'Region/Country/Area':['United States of America']*9,'Year':missing_years,\n",
    "                'Data':'Students enrolled in primary education (thousands)'*9,\n",
    "                'Value':[np.nan]*9,'Footnotes':[np.nan]*9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = pd.DataFrame(data=dict_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_USA=primary_enrollment_USA.append(df_missing,ignore_index=True,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_USA.sort_values(by='Year',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_USA.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_USA.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still the first value is unfilled. We can use `limit` and `limit_direction` parameters with `interpolate()` method to fill that.\n",
    "\n",
    "How did we know this? By searching on Google and looking at this Stackoverflow page. \n",
    "\n",
    "Always, search for solution to your problem and look for what has already been done and try to implement that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_USA.interpolate(method='linear',limit_direction='backward',limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(primary_enrollment_USA['Year'],primary_enrollment_USA['Enrollments (Thousands)'])\n",
    "plt.title(\"Enrollment in primary education\\nin the United States of America (in thousands)\",fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP data for India\n",
    "\n",
    "We will try to read the GDP data for India from a CSV file found in a World Bank portal. It is given to you and also hosted on the Gihub repo. \n",
    "\n",
    "But the Pandas `read_csv()` method will throw error if we try to read it normally. Let's see step-by-step how we can read useful information from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"../datasets/India_World_Bank_Info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can try `error_bad_lines=False` option in this kind of situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"../datasets/India_World_Bank_Info.csv\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearly, the delimiter in this file is not `,` but tab (`\\t`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"../datasets/India_World_Bank_Info.csv\",error_bad_lines=False,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, the first 4 rows do not seem to be useful, so we can use `skiprows` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.read_csv(\"../datasets/India_World_Bank_Info.csv\",error_bad_lines=False,delimiter='\\t',skiprows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closely examine the dataset\n",
    "In this file the columns are the yearly data and rows are various type of information. \n",
    "\n",
    "Upon examining the file with Excel we find that the column `Indicator Name` is the one with the name of the particular data type. \n",
    "\n",
    "We filter the dataset with the information we are interested in and also transpose (rows and columns gets interchanged) to make it similar format of our previous education dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3[df3['Indicator Name']=='GDP per capita (current US$)'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is no index, let's use `reset_index()` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First 3 rows are not useful. We can redefine the dataframe without them. And we re-index again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.drop([0,1,2],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's rename the columns properly (this is necessary for merging, which we will see shortly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.columns=['Year','GDP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It looks like that we have GDP data from 1960 onward. But we are interested in 2003 - 2016. Let's examine the last 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, we should be good with rows 43-56. Let's create a dataframe called `df_gdp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp=df4.iloc[[i for i in range(43,57)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to reset index again (for merging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `year` in this dataframe is not `int` type. So, it will have problem merging with the education dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp['Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `apply` method with Python built-in `int` function. Ignore any warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp['Year']=df_gdp['Year'].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now merge the two dataframes `primary_enrollment_india` and `df_gdp` on the `Year` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_with_gdp=primary_enrollment_india.merge(df_gdp,on='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_with_gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can drop the columns - `Data`, `Footnotes`, and `Region/Country/Area`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_with_gdp.drop(['Data','Footnotes','Region/Country/Area'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_with_gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-arrange the columns for proper viewing and presentation to a data scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_with_gdp = primary_enrollment_with_gdp[['Year','Enrollments (Thousands)','GDP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_enrollment_with_gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"India's GDP per capita vs primary education enrollment\",fontsize=16)\n",
    "plt.scatter(primary_enrollment_with_gdp['GDP'],\n",
    "            primary_enrollment_with_gdp['Enrollments (Thousands)'],\n",
    "           edgecolor='k',color='orange',s=200)\n",
    "plt.xlabel(\"GDP per capita (US $)\",fontsize=15)\n",
    "plt.ylabel(\"Primary enrollment (thousands)\",fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a database and writing this values in a table\n",
    "\n",
    "We start by importing the `sqlite3` module of Python and then use the `connect` function to connect to a database. \n",
    "\n",
    "If you already have some experience with database then you will notice that we are not using any server address, user name, password or similar kind of credentials to connect to a database. That is because in `sqlite3` we do not need them. The main database engine is embedded. But for a different database like Postgresql or MySQL we will need to connect to them using those credentials.\n",
    "\n",
    "We designate `Year` as the PRIMARY KEY of this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(\"Education_GDP.db\") as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE IF NOT EXISTS \\\n",
    "                   education_gdp(Year INT, Enrollment FLOAT, GDP FLOAT, PRIMARY KEY (Year))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we run a loop with the dataset rows one by one to insert them in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(\"Education_GDP.db\") as conn:\n",
    "    cursor = conn.cursor()\n",
    "    for i in range(14):\n",
    "        year = int(primary_enrollment_with_gdp.iloc[i]['Year'])\n",
    "        enrollment = primary_enrollment_with_gdp.iloc[i]['Enrollments (Thousands)']\n",
    "        gdp = primary_enrollment_with_gdp.iloc[i]['GDP']\n",
    "        #print(year,enrollment,gdp)\n",
    "        cursor.execute(\"INSERT INTO education_gdp (Year,Enrollment,GDP) VALUES(?,?,?)\",(year,enrollment,gdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we look at the current folder, we should see a file `Education_GDP.db` and if we can examine that using a database viewer program, we can see the data transferred there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this notebook, we examined a complete data wrangling flow including,\n",
    "* reading data from web and local drive,\n",
    "* filtering, \n",
    "* cleaning,\n",
    "* quick visualization\n",
    "* imputation,\n",
    "* indexing\n",
    "* merging\n",
    "* writing back to a database table\n",
    "\n",
    "We also wrote custom functions to transform some of the data and saw how to handle situations where we may get error reading the file.\n",
    "\n",
    "**Students are encouraged to try extracting various data from these files and answer their own questions about nations' socio-economic factors**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
